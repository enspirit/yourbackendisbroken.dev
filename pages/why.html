>{nav}
<section>
  <h1>Let's improve all backends</h1>
  <p>Whilst continuously working on software for many years, we've come to the conclusion
     that many teams could improve the quality of their software through
     better design and black-box testing of backend components.</p>
  <h2>In our opinion, a backend is broken when &hellip;</h2>
  <ol>
    <li>It becomes harder and harder to maintain and make evolve.</li>
    <li>It breaks its clients when released.</li>
    <li>It throws 500 errors everytime something is unexpected.</li>
    <li>It exposes technical details on errors.</li>
    <li>It has recurring performance problems.</li>
    <li>It requires looking at the code to discover the services.</li>
  </ol>
  <h2>Broken backends come with unneccessary costs</h2>
  <ol>
    <li>The software team is 10 times slower than it could be.</li>
    <li>By lack of quality, the backend will eventually be rewritten from scratch.</li>
    <li>A deadly security nightmare tends to wait around the corner.</li>
    <li>The lack of black-box design is a missed opportunity to think clearly about requirements.</li>
  </ol>
  <h2>We have observed that testing is not fully undertaken in most teams</h2>
  <ol>
    <li>Unit tests are often used, but are fined-grained and are sometimes brittle.</li>
    <li>Integration testing has unclear boundaries, and most teams skip them.</li>
    <li>End-to-end testing is often slow, and focuses on best case scenarios.</li>
    <li>Functional black-box testing is ... generally unknown.</li>
  </ol>
  <h2>Web services offer an opportunity to improve software quality</h2>
  <ol>
    <li>Web services correspond to high-level software operations and are therefore close to requirements.</li>
    <li>Therefore, they offer a great space for clear thinking and stable design.</li>
    <li>Being a public API by nature, web services call for robustness & security analysis.</li>
    <li>The HTTP protocol they all rely on is standard, rich enough, and technology agnostic.</li>
  </ol>
  <h2>Based on these observations, we are providing an open-source framework where&hellip;</h2>
  <ol>
    <li>Web services are specified in a simple, human-friendly, yet formal way.</li>
    <li>Checking if they meet their specification is as easy as using <code>curl</code>.</li>
    <li>PRE/POST contracts provide systematic testing coverage.</li>
    <li>A specification can also be turned to documentation, or used for API mocking, code generation, etc.</li>
  </ol>
  <h2>We think it is complementary to existing alternatives</h2>
  <ol>
    <li>Our focus is on software quality through specification and testing. We see <a href="https://swagger.io/" target="_blank">swagger</a> as complementary, with a focus on documentation and UI tools.</li>
    <li>We also think that specifications must be independent from the implementation, not derived from it as with <a href="https://swagger.io/openapi/" target="_blank">openapi</a>.</li>
    <li>We share with <a href="https://cucumber.io/" target="_blank">cucumber</a> the wish to be human-centric, not machine-centric.</li>
    <li>We want to fix an element of vocabulary, by distinguishing a <code>spec</code> from its <code>tests</code>.</li>
    <li>We stress the fact that functional testing is not about running best-case scenarios, but about testing the conformity of an implementation to a <code>spec</code>.</li>
  </ol>
  <h2>We hope you enjoy it, and welcome contributions, ideas, and feedback.</h2>
</section>
